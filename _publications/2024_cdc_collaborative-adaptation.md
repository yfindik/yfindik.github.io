---
title: "Collaborative Adaptation for Recovery from Unforeseen Malfunctions in Discrete and Continuous MARL Domains"
collection: publications
permalink: /publication/2024_cdc_collaborative-adaptation
excerpt: ''
date: 2024-12-16
venue: 'IEEE International Conference on Decision and Control (CDC)'
paperurl: https://arxiv.org/pdf/2407.19144
citation: '<b>Y. Findik</b>, H. Hasenfus, R. Azadeh. &quot;Collaborative Adaptation for Recovery from Unforeseen Malfunctions in Discrete and Continuous MARL Domains.&quot; <i>In proceeding 63rd IEEE Conference on Decision and Control (CDC), Milan, Italy, pp. xx-xx, Dec. 16-19, 2024</i>.'
---

Cooperative multi-agent learning plays a crucial role for developing effective strategies to achieve individual or shared objectives in multi-agent teams. In real-world settings, agents may face unexpected failures, such as a robot's leg malfunctioning or a teammate's battery running out. These malfunctions decrease the team's ability to accomplish assigned task(s), especially if they occur after the learning algorithms have already converged onto a collaborative strategy. Current leading approaches in Multi-Agent Reinforcement Learning (MARL) often recover slowly -- if at all -- from such malfunctions. To overcome this limitation, we present the Collaborative Adaptation (CA) framework, highlighting its unique capability to operate in both continuous and discrete domains. Our framework enhances the adaptability of agents to unexpected failures by integrating inter-agent relationships into their learning processes, thereby accelerating the recovery from malfunctions. We evaluated our framework's performance through experiments in both discrete and continuous environments. Empirical results reveal that in scenarios involving unforeseen malfunction, although state-of-the-art algorithms often converge on sub-optimal solutions the proposed CA framework mitigates and recovers more effectively.

<iframe width="420" height="315"
src="https://www.youtube.com/embed/-0Qd5jyRGIY">
</iframe>
